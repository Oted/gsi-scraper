var Extractors  = require('./extractors'),
    Validator   = require('validator'),
    Utils       = require('./utils.js'),
    internals   = {};

/**
 *  Constructor for the Plougher.
 */
function Plougher() {};

/**
 * Function used for scraping and extracting this function must be provided with 
 *  A variable being eith a complete html or an url
 *  A mapping for mapping the html
 *  A function which will be called when the result is ready
 */
Plougher.prototype.scrape = function(htmlOrUrl, config, done) {
    var that = this, jsonString = JSON.stringify(config, null, "");

    if (!htmlOrUrl) {
        return done(new Error('First parameter must be a valid html or a url'));
    }
    
    if (!config) {
		return done(new Error('The second parameter should be a configuration object.'));
	}

    if (!done) {
        return done(new Error('Scrape function must be provided with a callback.'));
    }

    //validate the config
    if (!Validator.isJSON(jsonString)) {
        return done(new Error('Config should be a valid JSON format.'));
    }

    this.config = config;
    
    //validate url
    if (!Validator.isURL(htmlOrUrl)) {
        this.html = htmlOrUrl;
        return internals.extract(this.html, this.config, done);
    }

    //if were here, the htmlOrUrl is url get it!
    Utils.getHtml(htmlOrUrl, function(err, html) {
        if (err) {
            return done(err);
        }
        
        if (!html) {
            return done(new Error('The url ' + htmlOrUrl + ' cound not be followed, please make sure its valid.'));
        }
        
        that.html = html;
        return internals.extract(html, that.config, done);
    });
};

/**
 *  A helper function for calling the actual extractor
 */
internals.extract = function(html, config, done) {
    var extractors = new Extractors(html, config);
    extractors.extract(done); 
};

module.exports = exports = Plougher;
